{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "import math\n",
    "import time\n",
    "import json\n",
    "import torch\n",
    "import hashlib\n",
    "import tempfile\n",
    "import bittensor as bt\n",
    "from types import SimpleNamespace\n",
    "from transformers import GPT2Config, GPT2LMHeadModel\n",
    "from transformers import LlamaForCausalLM, LlamaConfig, LlamaTokenizer\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "import io\n",
    "import os\n",
    "import math\n",
    "import time\n",
    "import boto3\n",
    "import torch\n",
    "import wandb\n",
    "import typer\n",
    "import argparse\n",
    "import tempfile\n",
    "import bittensor as bt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch.optim as optim\n",
    "from dotenv import dotenv_values\n",
    "from types import SimpleNamespace\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import GPT2Config, GPT2LMHeadModel\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "\n",
    "# Instantiate my S3 client.\n",
    "env_config = {**dotenv_values(\".env\"), **os.environ}\n",
    "AWS_ACCESS_KEY_ID = env_config.get('AWS_ACCESS_KEY_ID')\n",
    "AWS_SECRET_ACCESS_KEY = env_config.get('AWS_SECRET_ACCESS_KEY')\n",
    "client: boto3.client = boto3.client(\n",
    "    's3',\n",
    "    region_name='us-east-1',\n",
    "    aws_access_key_id = AWS_ACCESS_KEY_ID,\n",
    "    aws_secret_access_key = AWS_SECRET_ACCESS_KEY\n",
    ")\n",
    "bucket = 'decis'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common import get_latest_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "latest_master_meta = get_latest_metadata( 0, bt.subtensor('test').metagraph(212), bt.subtensor('test'), CLIENT = client )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "namespace(last_modified=1726004446,\n",
       "          blocks_since_modified=32,\n",
       "          bucket='decis',\n",
       "          filename='model-5F4UUMWF41GsLFvwVpigmoxTKVngDP6C7utvECgtQB83U3fJ-1726004438.pt',\n",
       "          metadata_filename='model-5F4UUMWF41GsLFvwVpigmoxTKVngDP6C7utvECgtQB83U3fJ-1726004438_metadata.json',\n",
       "          sequence_length=2048,\n",
       "          tokenizer_name='gpt2',\n",
       "          deltas=[{'last_modified': 1726004389,\n",
       "                   'blocks_since_modified': 2,\n",
       "                   'bucket': 'decis',\n",
       "                   'filename': 'model-5EkVGe9zdK4D1rdPD2qutAbU1HGNcjSt8ibsMQcWnPLNcsxn-1726004382.pt',\n",
       "                   'metadata_filename': 'model-5EkVGe9zdK4D1rdPD2qutAbU1HGNcjSt8ibsMQcWnPLNcsxn-1726004382_metadata.json',\n",
       "                   'master_hash': 'd15e331787bf1f251183313ada6b7a4a645e38959b468b6ae80957a8bd60ac81',\n",
       "                   'model_type': 'llama',\n",
       "                   'model_config': {'vocab_size': 50257,\n",
       "                    'max_position_embeddings': 2048,\n",
       "                    'hidden_size': 2040,\n",
       "                    'intermediate_size': 6144,\n",
       "                    'num_hidden_layers': 12,\n",
       "                    'num_attention_heads': 12,\n",
       "                    'num_key_value_heads': 12,\n",
       "                    'hidden_act': 'silu',\n",
       "                    'initializer_range': 0.02,\n",
       "                    'rms_norm_eps': 1e-06,\n",
       "                    'pretraining_tp': 1,\n",
       "                    'use_cache': True,\n",
       "                    'rope_theta': 10000.0,\n",
       "                    'rope_scaling': None,\n",
       "                    'attention_bias': False,\n",
       "                    'attention_dropout': 0.0,\n",
       "                    'mlp_bias': False,\n",
       "                    'return_dict': True,\n",
       "                    'output_hidden_states': False,\n",
       "                    'output_attentions': False,\n",
       "                    'torchscript': False,\n",
       "                    'torch_dtype': None,\n",
       "                    'use_bfloat16': False,\n",
       "                    'tf_legacy_loss': False,\n",
       "                    'pruned_heads': {},\n",
       "                    'tie_word_embeddings': False,\n",
       "                    'chunk_size_feed_forward': 0,\n",
       "                    'is_encoder_decoder': False,\n",
       "                    'is_decoder': False,\n",
       "                    'cross_attention_hidden_size': None,\n",
       "                    'add_cross_attention': False,\n",
       "                    'tie_encoder_decoder': False,\n",
       "                    'max_length': 20,\n",
       "                    'min_length': 0,\n",
       "                    'do_sample': False,\n",
       "                    'early_stopping': False,\n",
       "                    'num_beams': 1,\n",
       "                    'num_beam_groups': 1,\n",
       "                    'diversity_penalty': 0.0,\n",
       "                    'temperature': 1.0,\n",
       "                    'top_k': 50,\n",
       "                    'top_p': 1.0,\n",
       "                    'typical_p': 1.0,\n",
       "                    'repetition_penalty': 1.0,\n",
       "                    'length_penalty': 1.0,\n",
       "                    'no_repeat_ngram_size': 0,\n",
       "                    'encoder_no_repeat_ngram_size': 0,\n",
       "                    'bad_words_ids': None,\n",
       "                    'num_return_sequences': 1,\n",
       "                    'output_scores': False,\n",
       "                    'return_dict_in_generate': False,\n",
       "                    'forced_bos_token_id': None,\n",
       "                    'forced_eos_token_id': None,\n",
       "                    'remove_invalid_values': False,\n",
       "                    'exponential_decay_length_penalty': None,\n",
       "                    'suppress_tokens': None,\n",
       "                    'begin_suppress_tokens': None,\n",
       "                    'architectures': None,\n",
       "                    'finetuning_task': None,\n",
       "                    'id2label': {'0': 'LABEL_0', '1': 'LABEL_1'},\n",
       "                    'label2id': {'LABEL_0': 0, 'LABEL_1': 1},\n",
       "                    'tokenizer_class': None,\n",
       "                    'prefix': None,\n",
       "                    'bos_token_id': 1,\n",
       "                    'pad_token_id': None,\n",
       "                    'eos_token_id': 2,\n",
       "                    'sep_token_id': None,\n",
       "                    'decoder_start_token_id': None,\n",
       "                    'task_specific_params': None,\n",
       "                    'problem_type': None,\n",
       "                    '_name_or_path': '',\n",
       "                    'transformers_version': '4.44.2',\n",
       "                    'model_type': 'llama'},\n",
       "                   'model_hash': '2516c13994f28781c00bd93e969f9651720a1e5087384d958d8c88fc91285ee6',\n",
       "                   'uid': 1}],\n",
       "          model_type='llama',\n",
       "          model_config={'vocab_size': 50257,\n",
       "                        'max_position_embeddings': 2048,\n",
       "                        'hidden_size': 2040,\n",
       "                        'intermediate_size': 6144,\n",
       "                        'num_hidden_layers': 12,\n",
       "                        'num_attention_heads': 12,\n",
       "                        'num_key_value_heads': 12,\n",
       "                        'hidden_act': 'silu',\n",
       "                        'initializer_range': 0.02,\n",
       "                        'rms_norm_eps': 1e-06,\n",
       "                        'pretraining_tp': 1,\n",
       "                        'use_cache': True,\n",
       "                        'rope_theta': 10000.0,\n",
       "                        'rope_scaling': None,\n",
       "                        'attention_bias': False,\n",
       "                        'attention_dropout': 0.0,\n",
       "                        'mlp_bias': False,\n",
       "                        'return_dict': True,\n",
       "                        'output_hidden_states': False,\n",
       "                        'output_attentions': False,\n",
       "                        'torchscript': False,\n",
       "                        'torch_dtype': None,\n",
       "                        'use_bfloat16': False,\n",
       "                        'tf_legacy_loss': False,\n",
       "                        'pruned_heads': {},\n",
       "                        'tie_word_embeddings': False,\n",
       "                        'chunk_size_feed_forward': 0,\n",
       "                        'is_encoder_decoder': False,\n",
       "                        'is_decoder': False,\n",
       "                        'cross_attention_hidden_size': None,\n",
       "                        'add_cross_attention': False,\n",
       "                        'tie_encoder_decoder': False,\n",
       "                        'max_length': 20,\n",
       "                        'min_length': 0,\n",
       "                        'do_sample': False,\n",
       "                        'early_stopping': False,\n",
       "                        'num_beams': 1,\n",
       "                        'num_beam_groups': 1,\n",
       "                        'diversity_penalty': 0.0,\n",
       "                        'temperature': 1.0,\n",
       "                        'top_k': 50,\n",
       "                        'top_p': 1.0,\n",
       "                        'typical_p': 1.0,\n",
       "                        'repetition_penalty': 1.0,\n",
       "                        'length_penalty': 1.0,\n",
       "                        'no_repeat_ngram_size': 0,\n",
       "                        'encoder_no_repeat_ngram_size': 0,\n",
       "                        'bad_words_ids': None,\n",
       "                        'num_return_sequences': 1,\n",
       "                        'output_scores': False,\n",
       "                        'return_dict_in_generate': False,\n",
       "                        'forced_bos_token_id': None,\n",
       "                        'forced_eos_token_id': None,\n",
       "                        'remove_invalid_values': False,\n",
       "                        'exponential_decay_length_penalty': None,\n",
       "                        'suppress_tokens': None,\n",
       "                        'begin_suppress_tokens': None,\n",
       "                        'architectures': None,\n",
       "                        'finetuning_task': None,\n",
       "                        'id2label': {'0': 'LABEL_0', '1': 'LABEL_1'},\n",
       "                        'label2id': {'LABEL_0': 0, 'LABEL_1': 1},\n",
       "                        'tokenizer_class': None,\n",
       "                        'prefix': None,\n",
       "                        'bos_token_id': 1,\n",
       "                        'pad_token_id': None,\n",
       "                        'eos_token_id': 2,\n",
       "                        'sep_token_id': None,\n",
       "                        'decoder_start_token_id': None,\n",
       "                        'task_specific_params': None,\n",
       "                        'problem_type': None,\n",
       "                        '_name_or_path': '',\n",
       "                        'transformers_version': '4.44.2',\n",
       "                        'model_type': 'llama'},\n",
       "          model_hash='c4d1ada42ff12ca7de211c7e25e7c32c58cd9b18c6a603760447f13a4a6a3d81',\n",
       "          uid=0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latest_master_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['model-5D2uD6jYfLvpMPsngA3n4VAqxxmXSPtuku1TaXQnPdH3xohZ.pt', 'model-5D2uD6jYfLvpMPsngA3n4VAqxxmXSPtuku1TaXQnPdH3xohZ_metadata.json', 'model-5DHYeSMbG3n31Ev9e9BNZzBiWnSd9bkp5s8CdC3RR5aMUpAh.pt', 'model-5DHYeSMbG3n31Ev9e9BNZzBiWnSd9bkp5s8CdC3RR5aMUpAh_metadata.json', 'model-5EkVGe9zdK4D1rdPD2qutAbU1HGNcjSt8ibsMQcWnPLNcsxn.pt', 'model-5EkVGe9zdK4D1rdPD2qutAbU1HGNcjSt8ibsMQcWnPLNcsxn_metadata.json', 'model-5F4UUMWF41GsLFvwVpigmoxTKVngDP6C7utvECgtQB83U3fJ.pt', 'model-5F4UUMWF41GsLFvwVpigmoxTKVngDP6C7utvECgtQB83U3fJ_metadata.json', 'model-5GQw7vvU1tzQ8XCVE1FRf3As9MmTZasPZUoiSgDmnnEj9jaP.pt', 'model-5GQw7vvU1tzQ8XCVE1FRf3As9MmTZasPZUoiSgDmnnEj9jaP_metadata.json']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "response = client.list_objects_v2( Bucket = bucket )\n",
    "file_names = [content['Key'] for content in response.get('Contents', [])]\n",
    "print (file_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GPT2LMHeadModel( config = GPT2Config(\n",
    "    output_hidden_states = False, \n",
    "    n_positions = 1024\n",
    "))\n",
    "\n",
    "wallet = bt.wallet('Alice', 'Alice')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latest file with the largest block: gradients-5F4UUMWF41GsLFvwVpigmoxTKVngDP6C7utvECgtQB83U3fJ-11.pt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'gradients-5F4UUMWF41GsLFvwVpigmoxTKVngDP6C7utvECgtQB83U3fJ-11.pt'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_latest_metadata_file( hotkey ) -> str:\n",
    "    response = client.list_objects_v2( Bucket = bucket )\n",
    "    file_names = [content['Key'] for content in response.get('Contents', [])]\n",
    "    max_block = -1\n",
    "    latest_file = None\n",
    "    for file_name in file_names:\n",
    "        if file_name.startswith(f'gradients-{wallet.hotkey.ss58_address}-') and file_name.endswith('.pt'):\n",
    "            try:\n",
    "                block = int(file_name.split('-')[-1].split('.')[0])\n",
    "                if block > max_block:\n",
    "                    max_block = block\n",
    "                    latest_file = file_name\n",
    "            except ValueError:\n",
    "                continue\n",
    "    print(f\"Latest file with the largest block: {latest_file}\")\n",
    "    return latest_file\n",
    "\n",
    "get_latest_metadata_file( wallet.hotkey.ss58_address )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "block = 11\n",
    "filename = f'gradients-{wallet.hotkey.ss58_address}-{block}.pt'  # Filename for the gradients\n",
    "gradients = {name: param.data for name, param in model.named_parameters() if param.grad is not None}\n",
    "with io.BytesIO() as gradients_buffer:\n",
    "    torch.save(gradients, gradients_buffer)  # Save the gradients to the buffer\n",
    "    gradients_buffer.seek(0)  # Reset the buffer's position to the beginning\n",
    "    client.upload_fileobj(gradients_buffer, bucket, filename)  # Upload the gradients buffer to the storage service\n",
    "    client.put_object_acl(\n",
    "        Bucket=bucket,\n",
    "        Key=filename,\n",
    "        GrantRead='uri=\"http://acs.amazonaws.com/groups/global/AllUsers\"',\n",
    "        GrantReadACP='uri=\"http://acs.amazonaws.com/groups/global/AllUsers\"'\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[28502488, 22687085, 57214137, 41008498, 28242177, 9211837, 27743392, 14221368, 15647757, 57330970]\n"
     ]
    }
   ],
   "source": [
    "eval_pages = SubsetFineWebEdu2Loader.next_pages( offset = 10000003000, n_pages = 10, seed = 9 )\n",
    "print ([e[1] for e in eval_pages])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22687085, 57214137, 41008498, 28242177, 9211837, 27743392, 14221368, 15647757, 57330970, 47115201]\n"
     ]
    }
   ],
   "source": [
    "eval_pages = SubsetFineWebEdu2Loader.next_pages( offset = 10000003001, n_pages = 10, seed = 9 )\n",
    "print ([e[1] for e in eval_pages])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import random\n",
    "from transformers import AutoTokenizer\n",
    "from dataset import SubsetFineWebEdu2Loader\n",
    "tokenizer: AutoTokenizer = AutoTokenizer.from_pretrained( 'gpt2', verbose=False, clean_up_tokenization_spaces=True )\n",
    "tokenizer.pad_token = tokenizer.eos_token    \n",
    "\n",
    "\n",
    "eval_pages = SubsetFineWebEdu2Loader.next_pages( offset = 100000, n_pages = 10, seed = 10 )\n",
    "            \n",
    "# training_pages = [ random.choice( eval_pages ) ]\n",
    "# print ('training page', training_pages )\n",
    "\n",
    "# dataset = SubsetFineWebEdu2Loader(\n",
    "#     batch_size = 10,\n",
    "#     sequence_length = 2048,\n",
    "#     pages_info = training_pages,\n",
    "#     tokenizer = tokenizer\n",
    "# )\n",
    "# print (dataset)\n",
    "\n",
    "# for batch in dataset:\n",
    "#     print (batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
